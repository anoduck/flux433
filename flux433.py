#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2024  anoduck

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

# Much of the source code of this project was taken from:
# https://github.com/azrdev/rtl433_influx/.

from simple_parsing import parse
from dataclasses import dataclass
from alive_progress import alive_it
from configobj import ConfigObj
from configobj.validate import Validator
import pandas as pd
import uuid
import chardet
import json
from ast import literal_eval
from json.decoder import JSONDecodeError
from influxdb_client import InfluxDBClient, Point
from influxdb_client.client.write_api import SYNCHRONOUS
import os
from random import uniform
import sys
from datetime import datetime


cfg = """
## Configuration file for myflux
## https://github.com/anoduck/myflux
## MIT License = 'Copyright (c) 2024 Anoduck'
## This software is released under the MIT License.
## https: //opensource.org/licenses/MIT
## ----------------------------------------------------------------------------
## Please do not leave username and password unmodified and without quotes.
## --------------------------------------------------------------------------------
## *L00k* -- WARNING: ALL VALUES MUST BE CONTAINED IN SINGLE QUOTES -- *L00k*
## --------------------------------------------------------------------------------

# Organization configured in influxdb
org = string(default='replace with influxdb organization')

# API token generated by influxdb for organization
api = string(default='replace with generated API token')

# Bucket name for use in influxdb
bucket = string(default='replace with bucket name')
"""


@dataclass
class options:
    path: str = '~/Sandbox/ISM-Research'  # Path to Dir of JSON files or Json File
    test: bool = False  # Run in test mode


Options = parse(options, dest="Options")


field_dict = {
        'maybetemp': None,
        'temperature': None,
        'temperature_C': None,
        'temperature_C1': None,
        'temperature_C2': None,
        'temperature_2_C': None,
        'temperature_1_C': None,
        'temperature_F': None,
        'ptemperature_C': None,

        'pressure_bar': None,
        'pressure_hPa': None,
        'pressure_PSI': None,

        'humidity': None,
        'phumidity': None,
        'moisture': None,

        'windstrength': None,
        'gust': None,
        'average': None,
        'speed': None,
        'wind_gust': None,
        'wind_speed': None,

        'winddirection': None,
        'direction': None,
        'wind_direction': None,
        'wind_dir_deg': None,
        'wind_dir': None,

        'battery': None,
        'battery_mV': None,

        'rain': None,
        'rain_rate': None,
        'total_rain': None,
        'rain_total': None,
        'rainfall_accumulation': None,
        'raincounter_raw': None,

        'status': None,
        'state': None,
        'tristate': str,
        'button1': None,
        'button2': None,
        'button3': None,
        'button4': None,
        'flags': lambda x: int(str(x), base=16),
        'event': lambda x: int(str(x), base=16),
        'cmd': None,
        'cmd_id': None,
        'code': None,
        'num_rows': None,
        'unit': None,
        'id': None,
        'learn': None,
        'power0': None,
        'power1': None,
        'power2': None,
        'dim_value': None,
        'depth': None,
        'depth_cm': None,
        'energy': None,
        'len': None,
        'data': None,
        'repeat': None,
        'current': None,
        'interval': None,

        'heating': None,
        'heating_temp': None,
        'water': None,
}


def detect_encoding(file): 
    with open(file, 'rb') as encfile: 
        detector = chardet.universaldetector.UniversalDetector() 
        for line in encfile: 
            detector.feed(line) 
            if detector.done: 
                break
        detector.close() 
    return detector.result['encoding'] 





def sanitize_text(raw_name):
    text = str(raw_name)
    model_name = text.replace(" ", "_").replace("/", "_").replace(".", "_").replace("&", "")
    return model_name


def sanitize_time(time_string, file_ctime):
    clean = time_string.strip('s').strip('@')
    time_float = literal_eval(clean)
    jtime = file_ctime + time_float
    # jtime = round(jtime)
    return jtime


def sanitize_field(field):
    text = str(field)
    # return text.strip('{').strip('}').strip('"').strip("'").strip(':').strip(',').strip('\\')
    if '{' in text:
        return str(f'"{text}"')


def list_of_dicts(label, label_data):
    if len(label_data) > 1:
        row_list = []
        rows = label_data.get('rows')
        row_range = range(1, len(rows))
        for n in row_range:
            row = rows[n]
            row_id = label + str(n)
            entry_list = []
            for key, value in row.items():
                data = str(f'{key}={value}')
                entry_list.append(data)
            list_entry = row_id + str(entry_list)
            print(f'Row List for {label} is {list_entry}') # type: ignore
        row_list.append(list_entry)
        ret_val = row_list
    if len(label_data) == 1:
        print(label_data)
        row = label_data[0]
        entry_list = ''
        print(type(row))
        if isinstance(row, dict):
            print(f'Single row dict for {label} is {row}')
            for key, value in row.items():
                # value = sanitize_field(value)
                data = str(f'{key}={value}')
                entry_list += ',' + data
            if entry_list.startswith(','):
                entry_list = entry_list[1:]
            # ret_val = '{}={}'.format(label, entry_list)
            ret_val = entry_list
        elif isinstance(row, str):
            print(f'Single row string for {label} is {row}')
            # row = sanitize_field(row)
            ret_val = '{}={}'.format(label, row)
            ret_val = ret_val.replace(" ", "")
        else:
            print(f'Could not process {label} {row}')
    if isinstance(ret_val, list):
        return str(ret_val)
    elif isinstance(ret_val, str):
        return ret_val
    else:
        print(f'Could not process {label} {label_data}')
        
        
def sanitize_sets(set):
    if set.startswith(','):
        set = set[1:]
    return set


def load_files(config, path):
    """
    Completely rewrite this shit.
    After hours of troubleshooting, it finally dawned on me,
    the python library does not follow the influxdb line protocol spec.
    """
    org = config['org']
    api = config['api']
    bucket = config['bucket']
    print('Client parameters: Org={}, API={}, Bucket={}'.format(org, api, bucket))
    client = InfluxDBClient(url="http://127.0.0.1:8086",
                            token=api, org=org)
    write_api = client.write_api(write_options=SYNCHRONOUS)
    for file in path:
        encoding = detect_encoding(file)
        file_ctime = os.stat(file).st_ctime
        file_name = os.path.basename(file)
        with open(file, 'r', encoding=encoding, errors='ignore') as f:
            contents = f.readlines()
            for line in alive_it(contents):
                if not 'model' in line:
                    continue
                try:
                    json_dict = json.loads(line)
                except JSONDecodeError as e:
                    print("error {} decoding {}".format(e, f), file=sys.stderr)
                    print("Error encountered while processing: {}".format(file))
                    continue
                test_name = json_dict.pop('model')
                if test_name != 'name':
                    raw_name = test_name
                    model_name = sanitize_text(raw_name)
                else:
                    model_name = 'unknown' + str(round(uniform(1000, 999999)))
                time_string = json_dict.pop('time')
                jtime = sanitize_time(time_string, file_ctime)
                # --------------------------------------------------------------------
                # Fields: are not indexed, represent data, and should be unique
                # Tags: are indexed, represent metadata, and are not unique
                # --------------------------------------------------------------------
                ## Below is to be reworked
                fieldstr = str()
                if 'rows' in json_dict.keys():
                    row_data = json_dict.pop('rows')
                    ld_items = list_of_dicts(label='row', label_data=row_data)
                    fieldstr += ',' + str(ld_items)
                    print(f'After rows, fieldstr is {fieldstr}')
                if 'num_rows' in json_dict.keys():
                    del json_dict['num_rows']
                if 'codes' in json_dict.keys():
                    code_data = json_dict.pop('codes')
                    cd_items = list_of_dicts(label='code', label_data=code_data)
                    fieldstr += ',' + str(cd_items)
                    print(f'After codes, fieldstr is {fieldstr}')
                for key, value in field_dict.items():
                    if key in json_dict:
                        value = value or (lambda x : x)
                        try:
                            value = json_dict.pop(key)
                            set_entry = '{}={}'.format(key, value)
                            fieldstr += ',' + str(set_entry)
                            print(f'After {key}, fieldstr is {fieldstr}')
                        except Exception as e:
                            value = json_dict.get(key)
                            print('error {} mapping {}'.format(e, value))
                            continue
                # tag_set = str()
                # if len(json_dict) > 0:
                #     for key in json_dict.keys():
                #         value = json_dict.get(key)
                #         tag_entry = '{}={}'.format(key, str(value))
                #         tag_set += ',' + str(tag_entry)
                # fname_entry = '{}={}'.format('filename', file_name)
                # tag_set += ',' + str(fname_entry)
                file_name = sanitize_text(file_name)
                tag_set = str(f'source=json,file={file_name}')
                print(fieldstr)
                if len(fieldstr) == 0:
                    print('no fields to write', file=sys.stderr)
                    continue # invalid: we have no data
                tag_set = sanitize_sets(tag_set)
                fieldstr = sanitize_sets(fieldstr)
                # LPE = Line Protocol Entry
                # Example:
                # write_client.write(
                    # "my-bucket",
                    # "my-org",
                    # [
                        # "h2o_feet,location=coyote_creek water_level=2.0 2",
                        # "h2o_feet,location=coyote_creek water_level=3.0 3"
                        # ])
                LPE = str(f'{model_name},{tag_set} {fieldstr} {jtime}')
                print(f'Record to write as LPE: {LPE}')
                print(f'LPE type is {type(LPE)}')
                try:
                    write_api.write(bucket=bucket, record=LPE)
                except Exception as e:
                    print("error {} writing {}".format(e, LPE), file=sys.stderr)
                    exit(1)


def pathfinder(path):
    pathlist = []
    if os.path.isfile(path):
        pathlist.append(os.path.abspath(path))
    elif os.path.isdir(path):
        for root, dirs, files in os.walk(path):
            for name in files:
                if name.endswith('.json'):
                    pathlist.append(os.path.join(root, name))
    return pathlist


def create_test(config):
    org = config['org']
    api = config['api']
    bucket = config['bucket']
    print('Client parameters: Org={}, API={}, Bucket={}'.format(org, api, bucket))
    client = InfluxDBClient(url="http://127.0.0.1:8086",
                            token=api, org=org)
    write_api = client.write_api(write_options=SYNCHRONOUS)
    ## As Pandas Data Frame
    test_data = ''
    testdf = pd.read_csv(test_data)
    write_api.write("my-bucket", "my-org", record=testdf, 
                   data_frame_measurement_name='h2o_feet', 
                   data_frame_tag_columns=['location']
    ## As Line Protocol Entry
    timestamp = datetime.now().isoformat()
    data = "len=25,data=0147f98,code={25}0147f98"
    LPE = str(f"test_model,source=test_batch {data} {timestamp}")
    print(f'Record to write as LPE: {LPE}')
    print(f'LPE type is {type(LPE)}')
    pddata = ''
    try:
        write_api.write(bucket=bucket, record=LPE)
    except Exception as e:
        print("error {} writing {}".format(
            e, LPE), file=sys.stderr)
        exit(1)


def main():
    conf_file = "config.ini"
    conf_path = os.path.realpath(conf_file)
    config = ConfigObj()
    spec = cfg.split("\n")
    if not os.path.isfile(conf_file):
        config = ConfigObj(conf_file, configspec=spec)
        config.filename = conf_file
        vader = Validator()
        config.validate(vader, copy=True)
        config.write()
        print("Configuration file written to " + conf_path)
        sys.exit()
    else:
        config = ConfigObj(conf_file, configspec=spec)
    if Options.test:
        create_test(config)
    else:
        path = pathfinder(Options.path)
        load_files(config, path)


if __name__ == '__main__':
    main()
